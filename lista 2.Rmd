---
title: "Lista 2"
author: "Silvaneo Viera dos Santos Junior"
date: "9/5/2021"
output: pdf_document
header-includes:
  - \usepackage{cancel}
---

## Introdução

Nas questões a seguir, alternamos entre o uso das linguagens *R* (para gráficos) e *Python* (para cálculos um pouco mais intensivos), sendo que o pacote *reticulate* foi utilizado para intermediá-las, desta forma, a variável $py$ no $R$ armazena as variáveis do *Python* (ou seja, o comando *py\$exemplo* acessa a variável *exemplo* do *python* no *R*) e, de forma análoga, a variável *r* no *Python* armazena as variáveis do *R* (ou seja, o comando *r.exemplo* acessa a variável *exemplo* do *R* no *Python*). Para evitar confusões entre as linguagens, colocamos um indicativo de qual a linguagem usada no início de cada bloco de código.

Vale destacar também que usamos a versão $3.8.10$ do *Python* e os pacotes *Numpy* e *Tensorflow*, ademais usamos a versão $4.1.0$ do *R* com os pacotes *ggplot2*, *latex2exp*,*kableExtra* e *reticulate*.

Por último, ocorreram alguns problemas com a inicialização dos pesos e o treino da rede com o $Keras$, especificamente, os resultados obtidos não podiam ser reproduzidos, mesmo após fixar a semente de aleatoriedade. Para contornar este problema, foi necessário desabilitar o uso da $GPU$ durante o treino dos modelos, ademais a semente de aleatoriedade foi fixada em $13031998$.

```{r setup_r}
#### R ####
knitr::opts_chunk$set(echo = TRUE)

# Este código deve ser usado no RStudio integrado a algum Kernel do Python.
# A versão do RStudio usada é 1.4.1717.
# A versão do knitr usada é 1.33.
library(ggplot2)    # Versão 3.3.5
library(latex2exp)  # Versão 0.5.0
library(reticulate) # Versão 1.20
library(kableExtra) # Versão 1.3.4

sessionInfo()
```

```{python setup_python}
#### Python ####
# A versão do Python usada é 3.8.10.
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"
import tensorflow as tf # Versão 2.6.0
import numpy as np      # Versão 1.19.5
tf.random.set_seed(13031998)
```

## Questão 1

A cada item, para encontrar a região de fronteira de classificação, basta que encontremos $\vec{u}$ e $\vec{v}$ tais que:

$$
\begin{aligned}
\langle\vec{u},\vec{w}\rangle &=-b\\
\langle\vec{v},\vec{w}\rangle &=0
\end{aligned}
$$

Daí, para todo $t \in \mathbb{R}$, vale que:

$$
\sigma(\vec{w}^t(\vec{u}+t\vec{v})+b)=\sigma(\vec{w}^t\vec{u}+t\cancelto{0}{\vec{w}^t\vec{v}}+b)=\sigma(-b+b)=\sigma(0)=0.5
$$

Daí, obtemos a fronteira de classificação.

### a)

```{r}
#### R ####
u=matrix(c(1,1),2,1)
v=matrix(c(1,-1),2,1)
left_lim=u-v
right_lim=u+v

ggplot()+
  geom_line(aes(x=c(left_lim[1],right_lim[1]),
                y=c(left_lim[2],right_lim[2]),
                color='=0.5'),
            linetype='dashed')+
  geom_ribbon(aes(x=c(left_lim[1],right_lim[1]),
                ymax=c(left_lim[2],right_lim[2]),
                ymin=c(min(c(left_lim[2],right_lim[2])),min(c(left_lim[2],right_lim[2]))),
                fill='<0.5'),
              alpha=0.25)+
  geom_ribbon(aes(x=c(left_lim[1],right_lim[1]),
                ymin=c(left_lim[2],right_lim[2]),
                ymax=c(max(c(left_lim[2],right_lim[2])),max(c(left_lim[2],right_lim[2]))),
                fill='>0.5'),
              alpha=0.25)+
  scale_x_continuous(TeX('x_1'),expand=c(0,0))+
  scale_y_continuous(TeX('x_2'),expand=c(0,0))+
  labs(title='Fronteira de classificação para o item 1')+
  scale_color_manual('',values='black')+scale_fill_hue('')+theme_bw()
```
\pagebreak

### b)

```{r}
#### R ####
u=matrix(c(1,1),2,1)
v=matrix(c(1,0),2,1)
left_lim=u-v
right_lim=u+v

ggplot()+
  geom_line(aes(x=c(left_lim[1],right_lim[1]),
                y=c(left_lim[2],right_lim[2]),
                color='=0.5'),
            linetype='dashed')+
  geom_ribbon(aes(x=c(left_lim[1],right_lim[1]),
                ymax=c(left_lim[2],right_lim[2]),
                ymin=0,
                fill='<0.5'),
              alpha=0.25)+
  geom_ribbon(aes(x=c(left_lim[1],right_lim[1]),
                ymin=c(left_lim[2],right_lim[2]),
                ymax=2,
                fill='>0.5'),
              alpha=0.25)+
  scale_x_continuous(TeX('x_1'),expand=c(0,0))+
  scale_y_continuous(TeX('x_2'),expand=c(0,0))+
  labs(title='Fronteira de classificação para o item 2')+
  scale_color_manual('',values='black')+scale_fill_hue('')+theme_bw()
```
\pagebreak

### c)

```{r}
#### R ####
u=matrix(c(0,1),2,1)
v=matrix(c(1,2),2,1)
left_lim=u-v
right_lim=u+v

ggplot()+
  geom_line(aes(x=c(left_lim[1],right_lim[1]),
                y=c(left_lim[2],right_lim[2]),
                color='=0.5'),
            linetype='dashed')+
  geom_ribbon(aes(x=c(left_lim[1],right_lim[1]),
                ymax=c(left_lim[2],right_lim[2]),
                ymin=c(min(c(left_lim[2],right_lim[2])),min(c(left_lim[2],right_lim[2]))),
                fill='<0.5'),
              alpha=0.25)+
  geom_ribbon(aes(x=c(left_lim[1],right_lim[1]),
                ymin=c(left_lim[2],right_lim[2]),
                ymax=c(max(c(left_lim[2],right_lim[2])),max(c(left_lim[2],right_lim[2]))),
                fill='>0.5'),
              alpha=0.25)+
  scale_x_continuous(TeX('x_1'),expand=c(0,0))+
  scale_y_continuous(TeX('x_2'),expand=c(0,0))+
  labs(title='Fronteira de classificação para o item 3')+
  scale_color_manual('',values='black')+scale_fill_hue('')+theme_bw()
```

\pagebreak

### d)

```{r}
#### R ####
u=matrix(c(1,1),2,1)
v=matrix(c(1,-1),2,1)
left_lim=u-v
right_lim=u+v

ggplot()+
  geom_line(aes(x=c(left_lim[1],right_lim[1]),
                y=c(left_lim[2],right_lim[2]),
                color='=0.5'),
            linetype='dashed')+
  geom_ribbon(aes(x=c(left_lim[1],right_lim[1]),
                ymax=c(left_lim[2],right_lim[2]),
                ymin=c(min(c(left_lim[2],right_lim[2])),min(c(left_lim[2],right_lim[2]))),
                fill='>0.5'),
              alpha=0.25)+
  geom_ribbon(aes(x=c(left_lim[1],right_lim[1]),
                ymin=c(left_lim[2],right_lim[2]),
                ymax=c(max(c(left_lim[2],right_lim[2])),max(c(left_lim[2],right_lim[2]))),
                fill='<0.5'),
              alpha=0.25)+
  scale_x_continuous(TeX('x_1'),expand=c(0,0))+
  scale_y_continuous(TeX('x_2'),expand=c(0,0))+
  labs(title='Fronteira de classificação para o item 4')+
  scale_color_manual('',values='black')+scale_fill_hue('')+theme_bw()
```
\pagebreak

## Questão 2

Ao se inicializar todos os pesos e vieses com o mesmo valor temos que o gradiente para todos os pesos de uma mesma camada será igual, pois todos os neurônios da camada recebem o mesmo $input$, logo terão o mesmo $output$, ademais, como os pesos das camadas seguintes são todos iguais, temos que a influência de cada neurôniona saída da rede será a mesma, resultando então no mesmo gradiente para todos os pesos. O resultado final desta inicialização é que a rede será restrita a uma estrutura muito especifica que equivale a ter apenas um neurônio em cada camada, assim, a capacidade de aprendizado da rede será extremamente limitada.

## Questão 3

Podemos definir um $MLP$ com $k$ camadas como uma função $f$ com a seguinte estrutura:

$$
f(\vec{x})=A_k \cdot L_k \cdot A_{k-1} \cdot L_{k-1} \cdots A_2\cdot L_2\cdot A_1\cdot L_1(\vec{x}) 
$$

Onde $A_i$ é a função de ativação da camada $i$ e $L_i$ é a função afim associada com a camada $i$. Sabemos que o conjunta das funções afins é fechada para a operação de composição, daí, se $A_i$ é uma função linear (e portanto, afim), então $f$ também é uma função afim, logo podemos reescrever $f$ da seguinte forma:

$$
f(\vec{x})=W\vec{x}+\vec{b}
$$

Para alguma matriz $W$ e algum vetor $\vec{b}$, ou seja, esta rede neural com $k$ camadas teria o mesmo poder preditivo de uma rede com uma única camada.

\pagebreak

## Questão 4

### a)

As redes neurais treinadas nessa sessão possuem $64$ neurônios nas camadas latentes (com função de ativação *relu*) e $10$ neurônio na última camada (com função de ativação *softmax*), ademais, o treino foi feito usando *batch size* de $512$ e com método de usando a variante *Adam* do *SGD*, com taxa de aprendizado $10^{-3}$ e demais argumentos no *default*. Por último, a função de custo escolhida foi a *Categorical Cross Entropy*, definida como:

$$
Loss(x,y)=-[y\ln(x)+(1-y)\ln(1-x)]
$$

```{r}
#### R ####
data_train=read.csv('mnist_train.csv',header=F)
train_x=as.matrix(data_train[1:50000,2:785])
train_y=as.array(data_train[1:50000,1])

val_x=as.matrix(data_train[50001:60000,2:785])
val_y=as.array(data_train[50001:60000,1])

data_test=read.csv('mnist_test.csv',header=F)
test_x=as.matrix(data_test[,2:785])
test_y=as.array(data_test[,1])
```

```{python}
#### Python ####

# Classe para registrar o tempo de execução de cada epoch
class TimeHistory(tf.keras.callbacks.Callback):
  def on_train_begin(self, logs={}):
    self.times = []
  def on_epoch_begin(self, batch, logs={}):
    self.epoch_time_start = tf.timestamp()
  def on_epoch_end(self, batch, logs={}):
    self.times.append(tf.timestamp() - self.epoch_time_start)

models=[]
n_neurons=64
for i in range(1,5):
  models.append(tf.keras.Sequential(
    [tf.keras.layers.Dense(n_neurons, activation='relu') for j in range(i)]+
    [tf.keras.layers.Dense(10, activation='softmax')],
    name='Modelo_'+str(i))
    )
  models[-1].compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),
                optimizer=tf.keras.optimizers.Adam(1e-3),
                metrics=['accuracy'])
```
\pagebreak

```{python}
#### Python ####
time_callbacks=[TimeHistory(),TimeHistory(),TimeHistory(),TimeHistory()]
history=[]
n=100

for model,time_callback in zip(models,time_callbacks):
  history.append(
    model.fit(r.train_x,
              r.train_y,
              batch_size=512,
              epochs=n,
              validation_data=(r.val_x,r.val_y),
              verbose=0,
              shuffle=False,
              callbacks=[time_callback])
                    )
  print(model.summary())
  print('=================================================================\n');
                    
epoch1,time1=history[0].history['accuracy'],np.asarray(time_callbacks[0].times)
epoch2,time2=history[1].history['accuracy'],np.asarray(time_callbacks[1].times)
epoch3,time3=history[2].history['accuracy'],np.asarray(time_callbacks[2].times)
epoch4,time4=history[3].history['accuracy'],np.asarray(time_callbacks[3].times)

best_acur_table=np.asarray([[history[0].history['accuracy'][-1],
                             history[1].history['accuracy'][-1],
                             history[2].history['accuracy'][-1],
                             history[3].history['accuracy'][-1]],
                            [history[0].history['val_accuracy'][-1],
                             history[1].history['val_accuracy'][-1],
                             history[2].history['val_accuracy'][-1],
                             history[3].history['val_accuracy'][-1]]])
```
\pagebreak

### b)

No gráfico a seguir podemos verificar que o aumento das camadas latentes proporcionou melhorias na precisão ao longo do treino, o que, de fato, era esperado, pois uma arquitetura com mais camadas latentes tem uma capacidade maior de aprendizado. Observe que há uma separação bem clara entre os modelos com mais de $2$ camadas e os demais, de fato, parece que os modelos com $1$ e $2$ camadas são equivalentes e os modelos com $3$ e $4$ camadas também, havendo uma distinção clara entre estes agrupamentos.

```{r}
#### R ####

acur=c(py$epoch1,py$epoch2,py$epoch3,py$epoch4)
layer=c(rep(1,py$n),rep(2,py$n),rep(3,py$n),rep(4,py$n))

epochs=data.frame(precisao=acur,camadas=factor(layer))

ggplot(epochs)+
  geom_line(aes(x=rep(1:py$n,4),y=precisao,color=camadas))+
  #geom_point(aes(x=rep(1:py$n,4),y=precisao,color=camadas))+
  scale_x_continuous('Etapa')+
  scale_y_continuous('Acurácia')+
  scale_color_hue('Quantidade de\ncamadas latentes')+
  labs(title='Precisão ao longo das iterações')+
  theme_bw()
```
\pagebreak

### c)

No gráfico a seguir podemos verificar que os modelos com mais camadas latentes demoraram mais para treinar, mesmo com a quantidade de iterações fixas, naturalmente, isso se deve ao aumento na quantidade de parâmetros no modelo que faz cada etapa de treino ser ligeiramente mais longa. A partir do gráfico, podemos ver que a performance foi superior nos modelos que, de fato, treinaram por mais tempo, ademais, podemos ver que os modelos com mais camadas tiveram um aprendizado mais rápido desde o início do treino.

Vale destacar que o tempo total de treino não é muito diferente entre os modelos devido a diferença relativamente baixa entre a quantidade de parametros entre eles (cada camada latente após a primeira adiciona $4,160$ parâmetros no modelo, sendo que o modelo inicial já tem mais de $50,000$ parâmetros). Posto isto, para este caso particular, não há diferenças tão marcantes entre o gráfico deste item e do item anterior.

```{r}
#### R ####
t=c(0,0,0,0)
acur=c(0,0,0,0)
for(time in c(1:py$n)){
  t=c(t,
         sum(py$time1[1:time]),
         sum(py$time2[1:time]),
         sum(py$time3[1:time]),
         sum(py$time4[1:time]))
  acur=c(acur,
         py$epoch1[time],
         py$epoch2[time],
         py$epoch3[time],
         py$epoch4[time])
}
layer=rep(1:4,py$n+1)

epochs=data.frame(tempo=t,precisao=acur,camadas=factor(layer))

ggplot(epochs)+
  geom_line(aes(x=tempo,y=precisao,color=camadas))+
  #geom_point(aes(x=tempo,y=precisao,color=camadas))+
  scale_x_continuous('Tempo acumulado (em segundos)')+
  scale_y_continuous('Acurácia')+
  scale_color_hue('Quantidade de\ncamadas latentes')+
  labs(title='Precisão ao longo do tempo')+
  theme_bw()
```
\pagebreak

### d)

```{r}
#### R ####
tab_data=data.frame(1:4,
                    paste(round(py$best_acur_table[1,],4)*100,'\\%'),
                    paste(round(py$best_acur_table[2,],4)*100,'\\%'))

kable(tab_data,
      format="latex",
      align = "c",
      booktabs=T,
      escape=F,
      col.names=linebreak(c('Quantidade de\ncamadas latentes','Treino','Validação'))) %>%
  kable_styling(position = "center") %>%
  kable_styling(latex_options = "HOLD_position")
```
O modelo com $4$ camadas latentes teve o melhor desempenho, acertando $96.87\%$ do dígitos no conjunto de validação. Vale destacar que há uma diferença significativa entre a taxa de acertos no conjunto de treino e de validação, indicando que há, de fato, um grau razoável de *overfitting*.

### e)

```{python}
#### Python ####
ensemble_out=tf.math.reduce_sum([model.predict(r.val_x) for model in models],axis=0)
ensemble_pred=tf.cast(tf.argmax(ensemble_out,axis=1),'int32')

ensemble_acur=tf.math.reduce_mean(tf.cast(ensemble_pred==r.val_y,'float32'))
print(ensemble_acur.numpy())
```

Temos que o *ensemble* acertou $97.73\%$ dos dígitos no conjunto de teste, superando significativamente todos os outros modelos.

\pagebreak

### f)

O modelo com melhor performance foi o *ensemble*, daí, como vamos treinar novamente todos os modelos, posso muito bem exibir também a performance deles nos conjuntos de treino e teste.

```{python}
#### Python ####
models=[]
for i in range(1,5):
  models.append(tf.keras.Sequential(
    [tf.keras.layers.Dense(n_neurons, activation='relu') for j in range(i)]+
    [tf.keras.layers.Dense(10, activation='softmax')],
    name='Modelo_'+str(i))
    )
  models[-1].compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),
                optimizer=tf.keras.optimizers.Adam(1e-3),
                metrics=['accuracy'])
history=[]

for model,time_callback in zip(models,time_callbacks):
  history.append(
    model.fit(tf.concat([r.train_x,r.val_x],axis=0),
              tf.concat([r.train_y,r.val_y],axis=0),
              batch_size=512,
              epochs=n,
              verbose=0,
              validation_data=(r.test_x,r.test_y),
              shuffle=False)
                    );
                    
ensemble_out_train=tf.math.reduce_sum(
  [model.predict(tf.concat([r.train_x,r.val_x],axis=0)) for model in models],
  axis=0
  )
ensemble_pred_train=tf.cast(
  tf.argmax(ensemble_out_train,axis=1),
  'int32'
  )

ensemble_acur_train=tf.math.reduce_mean(
  tf.cast(
    ensemble_pred_train==tf.concat([r.train_y,r.val_y],axis=0),
    'float32'
    )
    )

ensemble_out_test=tf.math.reduce_sum(
  [model.predict(r.test_x) for model in models],
  axis=0)
ensemble_pred_test=tf.cast(
  tf.argmax(
    ensemble_out_test,
    axis=1
    ),
    'int32'
    )

ensemble_acur_test=tf.math.reduce_mean(
  tf.cast(
    ensemble_pred_test==r.test_y,
    'float32'
    )
    )
    
best_acur_table=np.asarray([[history[0].history['accuracy'][-1],
                             history[1].history['accuracy'][-1],
                             history[2].history['accuracy'][-1],
                             history[3].history['accuracy'][-1],
                             ensemble_acur_train],
                            [history[0].history['val_accuracy'][-1],
                             history[1].history['val_accuracy'][-1],
                             history[2].history['val_accuracy'][-1],
                             history[3].history['val_accuracy'][-1],
                             ensemble_acur_test]])
```

```{r}
#### R ####
tab_data=data.frame(c(paste('Modelo ',1:4),'Ensemble'),
                    paste(round(py$best_acur_table[1,],4)*100,'\\%'),
                    paste(round(py$best_acur_table[2,],4)*100,'\\%'))

tab_data=rbind(tab_data,
               linebreak(
                 c('Regressão Multi-\n nomial Logística','94.26\\%','92.66\\%')
                 )
               )

kable(tab_data,
      format="latex",
      align = "c",
      booktabs=T,
      escape=F,
      col.names=c('Modelo','Treino+Validação','Teste')) %>%
  kable_styling(position = "center") %>%
  kable_styling(latex_options = "HOLD_position")
```

Na lista anterior, o melhor resultado obtido no conjunto de teste foi $92.66\%$, em contrapartida, o modleo *ensemble* teve precisão de $97.82\%$ no conjunto de teste, um aumento muito grande em comparação ao modelo multinomial logístico.


